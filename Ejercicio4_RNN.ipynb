{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6858d97f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\burgo\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\burgo\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                576       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34250 (133.79 KB)\n",
      "Trainable params: 34250 (133.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\burgo\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5000\n",
      "WARNING:tensorflow:From C:\\Users\\burgo\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\burgo\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "369/369 [==============================] - 3s 3ms/step - loss: 1.6574 - accuracy: 0.5343 - val_loss: 1.2603 - val_accuracy: 0.5400\n",
      "Epoch 2/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 1.0807 - accuracy: 0.5567 - val_loss: 1.0045 - val_accuracy: 0.5461\n",
      "Epoch 3/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.5724 - val_loss: 0.9234 - val_accuracy: 0.5528\n",
      "Epoch 4/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.8728 - accuracy: 0.5779 - val_loss: 0.8821 - val_accuracy: 0.5630\n",
      "Epoch 5/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.8392 - accuracy: 0.5807 - val_loss: 0.8529 - val_accuracy: 0.5705\n",
      "Epoch 6/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.8142 - accuracy: 0.5863 - val_loss: 0.8289 - val_accuracy: 0.5725\n",
      "Epoch 7/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7935 - accuracy: 0.5952 - val_loss: 0.8094 - val_accuracy: 0.5745\n",
      "Epoch 8/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7751 - accuracy: 0.5992 - val_loss: 0.7902 - val_accuracy: 0.5935\n",
      "Epoch 9/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7587 - accuracy: 0.6085 - val_loss: 0.7744 - val_accuracy: 0.5962\n",
      "Epoch 10/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7434 - accuracy: 0.6157 - val_loss: 0.7604 - val_accuracy: 0.5996\n",
      "Epoch 11/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7288 - accuracy: 0.6235 - val_loss: 0.7447 - val_accuracy: 0.6192\n",
      "Epoch 12/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7157 - accuracy: 0.6329 - val_loss: 0.7330 - val_accuracy: 0.6186\n",
      "Epoch 13/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.7034 - accuracy: 0.6457 - val_loss: 0.7217 - val_accuracy: 0.6341\n",
      "Epoch 14/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.6601 - val_loss: 0.7109 - val_accuracy: 0.6382\n",
      "Epoch 15/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6823 - accuracy: 0.6641 - val_loss: 0.7038 - val_accuracy: 0.6402\n",
      "Epoch 16/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6733 - accuracy: 0.6707 - val_loss: 0.6961 - val_accuracy: 0.6484\n",
      "Epoch 17/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6659 - accuracy: 0.6777 - val_loss: 0.6885 - val_accuracy: 0.6416\n",
      "Epoch 18/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6591 - accuracy: 0.6817 - val_loss: 0.6822 - val_accuracy: 0.6497\n",
      "Epoch 19/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6530 - accuracy: 0.6833 - val_loss: 0.6767 - val_accuracy: 0.6531\n",
      "Epoch 20/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6483 - accuracy: 0.6850 - val_loss: 0.6717 - val_accuracy: 0.6606\n",
      "Epoch 21/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6436 - accuracy: 0.6917 - val_loss: 0.6681 - val_accuracy: 0.6599\n",
      "Epoch 22/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.6928 - val_loss: 0.6632 - val_accuracy: 0.6619\n",
      "Epoch 23/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6349 - accuracy: 0.6948 - val_loss: 0.6635 - val_accuracy: 0.6762\n",
      "Epoch 24/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6315 - accuracy: 0.7011 - val_loss: 0.6582 - val_accuracy: 0.6619\n",
      "Epoch 25/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6291 - accuracy: 0.7006 - val_loss: 0.6556 - val_accuracy: 0.6728\n",
      "Epoch 26/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7043 - val_loss: 0.6543 - val_accuracy: 0.6877\n",
      "Epoch 27/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6238 - accuracy: 0.7017 - val_loss: 0.6514 - val_accuracy: 0.6748\n",
      "Epoch 28/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6206 - accuracy: 0.7051 - val_loss: 0.6458 - val_accuracy: 0.6802\n",
      "Epoch 29/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7053 - val_loss: 0.6439 - val_accuracy: 0.6762\n",
      "Epoch 30/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6165 - accuracy: 0.7062 - val_loss: 0.6436 - val_accuracy: 0.6741\n",
      "Epoch 31/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6145 - accuracy: 0.7073 - val_loss: 0.6427 - val_accuracy: 0.6748\n",
      "Epoch 32/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6124 - accuracy: 0.7095 - val_loss: 0.6371 - val_accuracy: 0.6829\n",
      "Epoch 33/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.7112 - val_loss: 0.6358 - val_accuracy: 0.6836\n",
      "Epoch 34/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6093 - accuracy: 0.7092 - val_loss: 0.6352 - val_accuracy: 0.6795\n",
      "Epoch 35/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.7117 - val_loss: 0.6406 - val_accuracy: 0.6911\n",
      "Epoch 36/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6059 - accuracy: 0.7150 - val_loss: 0.6329 - val_accuracy: 0.6795\n",
      "Epoch 37/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6049 - accuracy: 0.7136 - val_loss: 0.6308 - val_accuracy: 0.6836\n",
      "Epoch 38/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.7114 - val_loss: 0.6316 - val_accuracy: 0.6944\n",
      "Epoch 39/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6020 - accuracy: 0.7128 - val_loss: 0.6280 - val_accuracy: 0.6809\n",
      "Epoch 40/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.7092 - val_loss: 0.6268 - val_accuracy: 0.6870\n",
      "Epoch 41/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.7131 - val_loss: 0.6258 - val_accuracy: 0.6728\n",
      "Epoch 42/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.7121 - val_loss: 0.6238 - val_accuracy: 0.6911\n",
      "Epoch 43/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5973 - accuracy: 0.7129 - val_loss: 0.6267 - val_accuracy: 0.6795\n",
      "Epoch 44/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7150 - val_loss: 0.6238 - val_accuracy: 0.6802\n",
      "Epoch 45/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.7138 - val_loss: 0.6208 - val_accuracy: 0.6802\n",
      "Epoch 46/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.7133 - val_loss: 0.6211 - val_accuracy: 0.6741\n",
      "Epoch 47/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.7111 - val_loss: 0.6253 - val_accuracy: 0.6789\n",
      "Epoch 48/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.7167 - val_loss: 0.6190 - val_accuracy: 0.6843\n",
      "Epoch 49/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.7131 - val_loss: 0.6168 - val_accuracy: 0.6843\n",
      "Epoch 50/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.7167 - val_loss: 0.6156 - val_accuracy: 0.6870\n",
      "Epoch 51/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7177 - val_loss: 0.6175 - val_accuracy: 0.6850\n",
      "Epoch 52/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7175 - val_loss: 0.6155 - val_accuracy: 0.6870\n",
      "Epoch 53/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.7151 - val_loss: 0.6134 - val_accuracy: 0.6877\n",
      "Epoch 54/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5868 - accuracy: 0.7172 - val_loss: 0.6212 - val_accuracy: 0.6890\n",
      "Epoch 55/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7163 - val_loss: 0.6226 - val_accuracy: 0.6863\n",
      "Epoch 56/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.7195 - val_loss: 0.6106 - val_accuracy: 0.6978\n",
      "Epoch 57/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7150 - val_loss: 0.6147 - val_accuracy: 0.6958\n",
      "Epoch 58/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5829 - accuracy: 0.7184 - val_loss: 0.6169 - val_accuracy: 0.6911\n",
      "Epoch 59/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5821 - accuracy: 0.7167 - val_loss: 0.6106 - val_accuracy: 0.6992\n",
      "Epoch 60/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5833 - accuracy: 0.7170 - val_loss: 0.6106 - val_accuracy: 0.6856\n",
      "Epoch 61/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.7211 - val_loss: 0.6110 - val_accuracy: 0.6904\n",
      "Epoch 62/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5814 - accuracy: 0.7145 - val_loss: 0.6117 - val_accuracy: 0.6809\n",
      "Epoch 63/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5800 - accuracy: 0.7209 - val_loss: 0.6081 - val_accuracy: 0.6836\n",
      "Epoch 64/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5786 - accuracy: 0.7172 - val_loss: 0.6065 - val_accuracy: 0.6911\n",
      "Epoch 65/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7223 - val_loss: 0.6092 - val_accuracy: 0.6951\n",
      "Epoch 66/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5778 - accuracy: 0.7204 - val_loss: 0.6068 - val_accuracy: 0.6917\n",
      "Epoch 67/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5763 - accuracy: 0.7212 - val_loss: 0.6059 - val_accuracy: 0.6931\n",
      "Epoch 68/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7184 - val_loss: 0.6075 - val_accuracy: 0.6829\n",
      "Epoch 69/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5742 - accuracy: 0.7216 - val_loss: 0.6046 - val_accuracy: 0.7019\n",
      "Epoch 70/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7204 - val_loss: 0.6013 - val_accuracy: 0.6985\n",
      "Epoch 71/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7217 - val_loss: 0.6058 - val_accuracy: 0.6843\n",
      "Epoch 72/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5720 - accuracy: 0.7214 - val_loss: 0.6063 - val_accuracy: 0.6992\n",
      "Epoch 73/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5706 - accuracy: 0.7255 - val_loss: 0.6196 - val_accuracy: 0.6856\n",
      "Epoch 74/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7255 - val_loss: 0.6001 - val_accuracy: 0.6958\n",
      "Epoch 75/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5699 - accuracy: 0.7255 - val_loss: 0.5980 - val_accuracy: 0.7005\n",
      "Epoch 76/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7212 - val_loss: 0.6070 - val_accuracy: 0.6877\n",
      "Epoch 77/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7253 - val_loss: 0.6028 - val_accuracy: 0.6944\n",
      "Epoch 78/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7265 - val_loss: 0.6024 - val_accuracy: 0.6944\n",
      "Epoch 79/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7223 - val_loss: 0.5982 - val_accuracy: 0.6931\n",
      "Epoch 80/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7250 - val_loss: 0.6014 - val_accuracy: 0.6985\n",
      "Epoch 81/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7238 - val_loss: 0.5957 - val_accuracy: 0.6944\n",
      "Epoch 82/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7302 - val_loss: 0.6005 - val_accuracy: 0.6972\n",
      "Epoch 83/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5661 - accuracy: 0.7250 - val_loss: 0.5955 - val_accuracy: 0.6972\n",
      "Epoch 84/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7317 - val_loss: 0.6070 - val_accuracy: 0.6850\n",
      "Epoch 85/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7258 - val_loss: 0.5962 - val_accuracy: 0.7012\n",
      "Epoch 86/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7284 - val_loss: 0.5947 - val_accuracy: 0.6992\n",
      "Epoch 87/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5648 - accuracy: 0.7278 - val_loss: 0.5942 - val_accuracy: 0.6958\n",
      "Epoch 88/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7275 - val_loss: 0.5915 - val_accuracy: 0.7019\n",
      "Epoch 89/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7316 - val_loss: 0.5988 - val_accuracy: 0.6809\n",
      "Epoch 90/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7258 - val_loss: 0.5964 - val_accuracy: 0.6924\n",
      "Epoch 91/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.7312 - val_loss: 0.6003 - val_accuracy: 0.6944\n",
      "Epoch 92/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5610 - accuracy: 0.7331 - val_loss: 0.5950 - val_accuracy: 0.6985\n",
      "Epoch 93/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7329 - val_loss: 0.5978 - val_accuracy: 0.6924\n",
      "Epoch 94/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5613 - accuracy: 0.7336 - val_loss: 0.5958 - val_accuracy: 0.7012\n",
      "Epoch 95/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5590 - accuracy: 0.7317 - val_loss: 0.5926 - val_accuracy: 0.6944\n",
      "Epoch 96/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7348 - val_loss: 0.5947 - val_accuracy: 0.6924\n",
      "Epoch 97/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5588 - accuracy: 0.7333 - val_loss: 0.5980 - val_accuracy: 0.6958\n",
      "Epoch 98/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7324 - val_loss: 0.5883 - val_accuracy: 0.7066\n",
      "Epoch 99/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7304 - val_loss: 0.5919 - val_accuracy: 0.6965\n",
      "Epoch 100/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7353 - val_loss: 0.5890 - val_accuracy: 0.7039\n",
      "Epoch 101/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5571 - accuracy: 0.7382 - val_loss: 0.5907 - val_accuracy: 0.7026\n",
      "Epoch 102/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5564 - accuracy: 0.7319 - val_loss: 0.5908 - val_accuracy: 0.6938\n",
      "Epoch 103/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5554 - accuracy: 0.7348 - val_loss: 0.5858 - val_accuracy: 0.7066\n",
      "Epoch 104/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7331 - val_loss: 0.5923 - val_accuracy: 0.7005\n",
      "Epoch 105/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7360 - val_loss: 0.5859 - val_accuracy: 0.7053\n",
      "Epoch 106/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7367 - val_loss: 0.5911 - val_accuracy: 0.6985\n",
      "Epoch 107/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.7360 - val_loss: 0.6051 - val_accuracy: 0.6999\n",
      "Epoch 108/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7372 - val_loss: 0.5852 - val_accuracy: 0.7026\n",
      "Epoch 109/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.7392 - val_loss: 0.5878 - val_accuracy: 0.7060\n",
      "Epoch 110/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.7372 - val_loss: 0.5939 - val_accuracy: 0.6992\n",
      "Epoch 111/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7346 - val_loss: 0.5869 - val_accuracy: 0.6992\n",
      "Epoch 112/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7336 - val_loss: 0.5940 - val_accuracy: 0.7060\n",
      "Epoch 113/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7395 - val_loss: 0.5867 - val_accuracy: 0.7026\n",
      "Epoch 114/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7400 - val_loss: 0.5851 - val_accuracy: 0.7012\n",
      "Epoch 115/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5513 - accuracy: 0.7372 - val_loss: 0.5829 - val_accuracy: 0.7087\n",
      "Epoch 116/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7404 - val_loss: 0.5888 - val_accuracy: 0.6992\n",
      "Epoch 117/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7421 - val_loss: 0.5903 - val_accuracy: 0.6951\n",
      "Epoch 118/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5510 - accuracy: 0.7355 - val_loss: 0.5855 - val_accuracy: 0.7005\n",
      "Epoch 119/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7372 - val_loss: 0.5893 - val_accuracy: 0.7019\n",
      "Epoch 120/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7385 - val_loss: 0.5883 - val_accuracy: 0.7046\n",
      "Epoch 121/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5492 - accuracy: 0.7407 - val_loss: 0.5833 - val_accuracy: 0.7127\n",
      "Epoch 122/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7406 - val_loss: 0.5854 - val_accuracy: 0.7019\n",
      "Epoch 123/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7406 - val_loss: 0.5886 - val_accuracy: 0.7046\n",
      "Epoch 124/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7409 - val_loss: 0.5892 - val_accuracy: 0.7087\n",
      "Epoch 125/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7355 - val_loss: 0.5811 - val_accuracy: 0.7087\n",
      "Epoch 126/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7399 - val_loss: 0.5818 - val_accuracy: 0.7100\n",
      "Epoch 127/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7429 - val_loss: 0.5858 - val_accuracy: 0.7005\n",
      "Epoch 128/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7372 - val_loss: 0.5815 - val_accuracy: 0.7066\n",
      "Epoch 129/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7417 - val_loss: 0.5790 - val_accuracy: 0.7073\n",
      "Epoch 130/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7431 - val_loss: 0.5820 - val_accuracy: 0.7060\n",
      "Epoch 131/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7424 - val_loss: 0.5898 - val_accuracy: 0.7073\n",
      "Epoch 132/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7460 - val_loss: 0.5838 - val_accuracy: 0.7005\n",
      "Epoch 133/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7445 - val_loss: 0.5877 - val_accuracy: 0.7209\n",
      "Epoch 134/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7446 - val_loss: 0.5940 - val_accuracy: 0.6992\n",
      "Epoch 135/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7441 - val_loss: 0.5838 - val_accuracy: 0.7073\n",
      "Epoch 136/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7424 - val_loss: 0.5747 - val_accuracy: 0.7154\n",
      "Epoch 137/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5442 - accuracy: 0.7441 - val_loss: 0.5811 - val_accuracy: 0.7134\n",
      "Epoch 138/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7448 - val_loss: 0.5821 - val_accuracy: 0.7012\n",
      "Epoch 139/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7482 - val_loss: 0.5767 - val_accuracy: 0.7073\n",
      "Epoch 140/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7480 - val_loss: 0.5860 - val_accuracy: 0.7073\n",
      "Epoch 141/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7412 - val_loss: 0.5790 - val_accuracy: 0.7141\n",
      "Epoch 142/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7433 - val_loss: 0.5747 - val_accuracy: 0.7161\n",
      "Epoch 143/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7422 - val_loss: 0.5882 - val_accuracy: 0.7046\n",
      "Epoch 144/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7404 - val_loss: 0.5783 - val_accuracy: 0.7175\n",
      "Epoch 145/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5430 - accuracy: 0.7439 - val_loss: 0.5746 - val_accuracy: 0.7134\n",
      "Epoch 146/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7443 - val_loss: 0.5747 - val_accuracy: 0.7182\n",
      "Epoch 147/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7485 - val_loss: 0.5793 - val_accuracy: 0.7087\n",
      "Epoch 148/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7472 - val_loss: 0.5786 - val_accuracy: 0.7060\n",
      "Epoch 149/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7458 - val_loss: 0.5906 - val_accuracy: 0.6944\n",
      "Epoch 150/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7416 - val_loss: 0.5760 - val_accuracy: 0.7114\n",
      "Epoch 151/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7483 - val_loss: 0.5743 - val_accuracy: 0.7195\n",
      "Epoch 152/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7453 - val_loss: 0.5905 - val_accuracy: 0.7080\n",
      "Epoch 153/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7468 - val_loss: 0.5790 - val_accuracy: 0.7222\n",
      "Epoch 154/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7467 - val_loss: 0.5705 - val_accuracy: 0.7195\n",
      "Epoch 155/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7461 - val_loss: 0.5708 - val_accuracy: 0.7161\n",
      "Epoch 156/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7445 - val_loss: 0.5822 - val_accuracy: 0.7114\n",
      "Epoch 157/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7477 - val_loss: 0.5866 - val_accuracy: 0.7039\n",
      "Epoch 158/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7458 - val_loss: 0.5813 - val_accuracy: 0.7053\n",
      "Epoch 159/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7429 - val_loss: 0.5749 - val_accuracy: 0.7134\n",
      "Epoch 160/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7478 - val_loss: 0.5742 - val_accuracy: 0.7209\n",
      "Epoch 161/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7417 - val_loss: 0.5776 - val_accuracy: 0.7100\n",
      "Epoch 162/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7494 - val_loss: 0.5719 - val_accuracy: 0.7209\n",
      "Epoch 163/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7506 - val_loss: 0.5736 - val_accuracy: 0.7195\n",
      "Epoch 164/5000\n",
      "369/369 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7494 - val_loss: 0.5855 - val_accuracy: 0.7060\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "path = \"dataset/normalized/\"\n",
    "\n",
    "df = pd.read_csv(path + \"kart.csv\")\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop('action', axis=1)\n",
    "y = df['action']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Assuming x_train and x_val are NumPy arrays\n",
    "min_value = np.min(np.concatenate([x_train, x_val]))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Métrica a monitorear (puede ser 'val_accuracy', 'val_loss', etc.)\n",
    "    patience=10,          # Número de épocas sin mejora antes de detener el entrenamiento\n",
    "    restore_best_weights=True  # Restaura los pesos del modelo al mejor logrado durante el entrenamiento\n",
    ")\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(8,)))\n",
    "\n",
    "# Agrega una capa de Reshape para agregar la dimensión de los pasos de tiempo\n",
    "model.add(layers.Reshape((1, 64)))\n",
    "\n",
    "# Capa LSTM\n",
    "model.add(layers.LSTM(64))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=5000,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
